{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is StlyeGAN2-ADA-pytorch for black and white images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataset\n",
    "I used more than few thounds images to generate network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/4432 [00:00<?, ?it/s]{'width': 512, 'height': 512, 'channels': 1}\n",
      "100%|███████████████████████████████████████| 4432/4432 [01:08<00:00, 64.81it/s]\n"
     ]
    }
   ],
   "source": [
    "!python dataset_tool_gray.py --source= source images --dest= ./dataset_floder.zip --transform=center-crop --width=512 --height=512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python dataset_tool_gray.py --source=../DCGAN/Knee_GAN/new_images/1/1 --dest=./datasets/0323oiaclassify1.zip --transform=center-crop --width=512 --height=512\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --dry run is for check parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --outdir=./outdir --data=dataset_floder.zip --gpus=2 --cfg=auto --kimg =1000 --dry-run\n",
    "!python train.py --outdir=./outdir--data= dataset_floder.zip --gpus=N_GPU --cfg=auto \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --outdir=./training-runs --data=./datasets/0323oiaclassify1.zip  --gpus=2 --cfg=auto \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python generate_gray.py --outdir=./output_folder --seeds=number of seeds --network= path to netwrok "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python generate_gray.py --outdir=./output --seeds=0-1000 --network=./training-runs/00000-sunh-auto2-kimg1000/network-snapshot-000800.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calc_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network from \"./training-runs/00000-sunh-auto2-kimg1000/network-snapshot-001000.pkl\"...\n",
      "Dataset options:\n",
      "{\n",
      "  \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
      "  \"path\": \"./datasets/sunh.zip\",\n",
      "  \"resolution\": 512,\n",
      "  \"use_labels\": false,\n",
      "  \"xflip\": true\n",
      "}\n",
      "Launching processes...\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "\n",
      "Generator             Parameters  Buffers  Output shape        Datatype\n",
      "---                   ---         ---      ---                 ---     \n",
      "mapping.fc0           262656      -        [1, 512]            float32 \n",
      "mapping.fc1           262656      -        [1, 512]            float32 \n",
      "mapping               -           512      [1, 16, 512]        float32 \n",
      "synthesis.b4.conv1    2622465     32       [1, 512, 4, 4]      float32 \n",
      "synthesis.b4.torgb    263169      -        [1, 1, 4, 4]        float32 \n",
      "synthesis.b4:0        8192        16       [1, 512, 4, 4]      float32 \n",
      "synthesis.b4:1        -           -        [1, 512, 4, 4]      float32 \n",
      "synthesis.b8.conv0    2622465     80       [1, 512, 8, 8]      float32 \n",
      "synthesis.b8.conv1    2622465     80       [1, 512, 8, 8]      float32 \n",
      "synthesis.b8.torgb    263169      -        [1, 1, 8, 8]        float32 \n",
      "synthesis.b8:0        -           16       [1, 512, 8, 8]      float32 \n",
      "synthesis.b8:1        -           -        [1, 512, 8, 8]      float32 \n",
      "synthesis.b16.conv0   2622465     272      [1, 512, 16, 16]    float32 \n",
      "synthesis.b16.conv1   2622465     272      [1, 512, 16, 16]    float32 \n",
      "synthesis.b16.torgb   263169      -        [1, 1, 16, 16]      float32 \n",
      "synthesis.b16:0       -           16       [1, 512, 16, 16]    float32 \n",
      "synthesis.b16:1       -           -        [1, 512, 16, 16]    float32 \n",
      "synthesis.b32.conv0   2622465     1040     [1, 512, 32, 32]    float32 \n",
      "synthesis.b32.conv1   2622465     1040     [1, 512, 32, 32]    float32 \n",
      "synthesis.b32.torgb   263169      -        [1, 1, 32, 32]      float32 \n",
      "synthesis.b32:0       -           16       [1, 512, 32, 32]    float32 \n",
      "synthesis.b32:1       -           -        [1, 512, 32, 32]    float32 \n",
      "synthesis.b64.conv0   2622465     4112     [1, 512, 64, 64]    float16 \n",
      "synthesis.b64.conv1   2622465     4112     [1, 512, 64, 64]    float16 \n",
      "synthesis.b64.torgb   263169      -        [1, 1, 64, 64]      float16 \n",
      "synthesis.b64:0       -           16       [1, 512, 64, 64]    float16 \n",
      "synthesis.b64:1       -           -        [1, 512, 64, 64]    float32 \n",
      "synthesis.b128.conv0  1442561     16400    [1, 256, 128, 128]  float16 \n",
      "synthesis.b128.conv1  721409      16400    [1, 256, 128, 128]  float16 \n",
      "synthesis.b128.torgb  131585      -        [1, 1, 128, 128]    float16 \n",
      "synthesis.b128:0      -           16       [1, 256, 128, 128]  float16 \n",
      "synthesis.b128:1      -           -        [1, 256, 128, 128]  float32 \n",
      "synthesis.b256.conv0  426369      65552    [1, 128, 256, 256]  float16 \n",
      "synthesis.b256.conv1  213249      65552    [1, 128, 256, 256]  float16 \n",
      "synthesis.b256.torgb  65793       -        [1, 1, 256, 256]    float16 \n",
      "synthesis.b256:0      -           16       [1, 128, 256, 256]  float16 \n",
      "synthesis.b256:1      -           -        [1, 128, 256, 256]  float32 \n",
      "synthesis.b512.conv0  139457      262160   [1, 64, 512, 512]   float16 \n",
      "synthesis.b512.conv1  69761       262160   [1, 64, 512, 512]   float16 \n",
      "synthesis.b512.torgb  32897       -        [1, 1, 512, 512]    float16 \n",
      "synthesis.b512:0      -           16       [1, 64, 512, 512]   float16 \n",
      "synthesis.b512:1      -           -        [1, 64, 512, 512]   float32 \n",
      "---                   ---         ---      ---                 ---     \n",
      "Total                 28694615    699904   -                   -       \n",
      "\n",
      "Calculating fid50k_full...\n",
      "dataset features    items 1024    time 9s           ms/item 8.36\n",
      "dataset features    items 2048    time 12s          ms/item 3.45\n",
      "dataset features    items 3072    time 15s          ms/item 3.22\n",
      "dataset features    items 4096    time 19s          ms/item 3.29\n",
      "dataset features    items 5120    time 22s          ms/item 3.27\n",
      "dataset features    items 6144    time 26s          ms/item 3.38\n",
      "dataset features    items 7168    time 29s          ms/item 3.24\n",
      "dataset features    items 8192    time 32s          ms/item 3.29\n",
      "dataset features    items 9216    time 36s          ms/item 3.23\n",
      "dataset features    items 10240   time 39s          ms/item 3.22\n",
      "dataset features    items 10809   time 42s          ms/item 5.14\n",
      "generator features  items 1024    time 23s          ms/item 22.93\n",
      "generator features  items 2048    time 45s          ms/item 20.75\n",
      "generator features  items 3072    time 1m 06s       ms/item 20.93\n",
      "generator features  items 4096    time 1m 27s       ms/item 20.81\n",
      "generator features  items 5120    time 1m 48s       ms/item 20.07\n",
      "generator features  items 6144    time 2m 10s       ms/item 21.09\n",
      "generator features  items 7168    time 2m 31s       ms/item 21.14\n",
      "generator features  items 8192    time 2m 53s       ms/item 20.89\n",
      "generator features  items 9216    time 3m 14s       ms/item 20.80\n",
      "generator features  items 10240   time 3m 35s       ms/item 20.93\n",
      "generator features  items 11264   time 3m 57s       ms/item 20.80\n",
      "generator features  items 12288   time 4m 18s       ms/item 21.03\n",
      "generator features  items 13312   time 4m 40s       ms/item 20.91\n",
      "generator features  items 14336   time 5m 01s       ms/item 20.81\n",
      "generator features  items 15360   time 5m 22s       ms/item 20.92\n",
      "generator features  items 16384   time 5m 44s       ms/item 20.88\n",
      "generator features  items 17408   time 6m 05s       ms/item 20.98\n",
      "generator features  items 18432   time 6m 26s       ms/item 20.30\n",
      "generator features  items 19456   time 6m 48s       ms/item 21.06\n",
      "generator features  items 20480   time 7m 09s       ms/item 20.95\n",
      "generator features  items 21504   time 7m 30s       ms/item 20.78\n",
      "generator features  items 22528   time 7m 52s       ms/item 21.06\n",
      "generator features  items 23552   time 8m 13s       ms/item 20.82\n",
      "generator features  items 24576   time 8m 35s       ms/item 20.96\n",
      "generator features  items 25600   time 8m 56s       ms/item 20.96\n",
      "generator features  items 26624   time 9m 17s       ms/item 20.77\n",
      "generator features  items 27648   time 9m 39s       ms/item 21.19\n",
      "generator features  items 28672   time 10m 01s      ms/item 21.11\n",
      "generator features  items 29696   time 10m 22s      ms/item 21.06\n",
      "generator features  items 30720   time 10m 43s      ms/item 20.10\n",
      "generator features  items 31744   time 11m 04s      ms/item 20.97\n",
      "generator features  items 32768   time 11m 26s      ms/item 20.76\n",
      "generator features  items 33792   time 11m 47s      ms/item 21.00\n",
      "generator features  items 34816   time 12m 09s      ms/item 20.94\n",
      "generator features  items 35840   time 12m 30s      ms/item 20.81\n",
      "generator features  items 36864   time 12m 51s      ms/item 20.97\n",
      "generator features  items 37888   time 13m 13s      ms/item 20.83\n",
      "generator features  items 38912   time 13m 34s      ms/item 20.91\n",
      "generator features  items 39936   time 13m 56s      ms/item 21.11\n",
      "generator features  items 40960   time 14m 17s      ms/item 20.96\n",
      "generator features  items 41984   time 14m 39s      ms/item 21.21\n",
      "generator features  items 43008   time 14m 59s      ms/item 20.15\n",
      "generator features  items 44032   time 15m 21s      ms/item 21.22\n",
      "generator features  items 45056   time 15m 43s      ms/item 20.95\n",
      "generator features  items 46080   time 16m 04s      ms/item 20.99\n",
      "generator features  items 47104   time 16m 25s      ms/item 20.84\n",
      "generator features  items 48128   time 16m 47s      ms/item 20.93\n",
      "generator features  items 49152   time 17m 08s      ms/item 20.96\n",
      "generator features  items 50000   time 17m 27s      ms/item 22.09\n",
      "{\"results\": {\"fid50k_full\": 3.1131835824862097}, \"metric\": \"fid50k_full\", \"total_time\": 1096.7636423110962, \"total_time_str\": \"18m 17s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-001000.pkl\", \"timestamp\": 1612753167.062439}\n",
      "\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "!python calc_metrics.py --metrics=fid50k_full --data=dataset_floder.zip --mirror=1 --network= path to netwrok "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stlyle mixing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading networks from \"./training-runs/00000-sunh-auto2-kimg1000/network-snapshot-000800.pkl\"...\n",
      "Generating W vectors...\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      "Generating images...\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "Generating style-mixed images...\n",
      "Saving images...\n",
      "Saving image grid...\n"
     ]
    }
   ],
   "source": [
    "!python style_mixing_gray.py --outdir=stylemix --rows=1,6,10,11,13,22,25,34 --cols=37,39,38,35, 29 --network= path to netwrok "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projecter\n",
    "\n",
    "Projecting images to latent space\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python projector_gray.py --outdir=out --target=~/mytargetimg.png --network= path to netwrok "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "def zipdir(path, ziph):\n",
    "    # ziph is zipfile handle\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            ziph.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), os.path.join(path, '..')))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    zipf = zipfile.ZipFile('0331_class4_generated.zip', 'w', zipfile.ZIP_DEFLATED)\n",
    "    zipdir('./out0330', zipf)\n",
    "    zipf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
